from math import floor, ceil
from pathlib import Path
from glob import glob
import os

configfile: "workflow.yaml"

CHRS=["2L", "2R", "3L", "3R", "4", "X", "Y", "mitochondrion_genome"]

poolseq_path = Path(config["poolseq_sync_directory"])
other_path = Path(config["other_sync_directory"])

wd = Path(config["working_directory"])
nJobs = config["poolsnp_jobs"]

input_sync_files = [str(poolseq_path / file) for file in os.listdir(poolseq_path)]
if config["popSet"] == "all":
    input_sync_files += [str(other_path / file) for file in os.listdir(other_path)]

log_dir = wd / "logs"
if not log_dir.exists():
    log_dir.mkdir()

job_file_path = wd / "poolSNP_jobs.csv"
if not job_file_path.exists():
    chr_lens = dict()
    with open(config["script_directory"] + "/holo_dmel_6.12.fa.fai") as src:
        for line in src.readlines():
            line = line.split()
            if line[0] in CHRS:
                chr_lens[line[0]] = int(line[1])
            if len(chr_lens.keys()) == len(CHRS):
                break
    total_len = sum(chr_lens.values())
    with open(wd / "poolSNP_jobs.csv", "w") as dest:
        for chrom in CHRS:
            chrom_len = 40000 #chr_lens[chrom]
            num_jobs = 100 #floor( ( chrom_len / total_len ) * nJobs) + 1
            step_size = ceil(chrom_len / num_jobs)
            for ix in range(1, chrom_len+1, step_size):
                start = ix
                stop = min(chrom_len, ix + step_size - 1)
                dest.write(f"{chrom},{start},{stop}\n")

rule all:
    input:
        expand("{wd}/dest.{popset}.{method}.{maf}.{mac}.{version}.ann.vcf.gz", \
                wd=config["working_directory"], \
                popset=config["popSet"], \
                method=config["method"], \
                maf=config["maf"], \
                mac=config["mac"], \
                version=config["version"])

# rule makeJobs:
#     output: expand("{wd}/poolSNP_jobs.csv", wd=config["working_directory"])
#     shell: "run_makeJobs.sh {config[working_directory]} {config[make_jobs_count]}"

# rule setupConfigDependencies:
#     output: temp(expand("{popset}.{method}.{maf}.{mac}.{version}.conf.temp", \
#                  popset=config["popSet"], \
#                  method=config["method"], \
#                  maf=config["maf"], \
#                  mac=config["mac"], \
#                  version=config["version"]))
#     shell: "touch {output}"

rule runPoolSnp:
    input:
        job_file=f"{config['working_directory']}/poolSNP_jobs.csv",
        input_files=input_sync_files
    output:
        expand("{wd}/sub_vcfs/{{jobid}}.{{popset}}.{{method}}.{{maf}}.{{mac}}.{{version}}.vcf.gz", wd=config['working_directory'])
        # expand("{wd}/sub_vcfs/{jobid}.{{popset}}.{{method}}.{{maf}}.{{mac}}.{{version}}.vcf.gz", wd=config['working_directory'], jobid=job_ids)
    # resources:
        # array_size=1 #len(open(f"{config['working_directory']}/poolSNP_jobs.csv").readlines())
    # shell : "bash run_poolsnp.sh {config[popSet]} {config[method]} {config[maf]} {config[mac]} {config[version]} poolSNP_jobs.csv {config[script_directory]} {config[working_directory]} {config[other_sync_directory]} {config[poolseq_sync_directory]}"
    shell : "bash run_poolsnp.sh {config[popSet]} {config[method]} {config[maf]} {config[mac]} {config[version]} {wildcards.jobid} {config[script_directory]} {config[working_directory]} {config[other_sync_directory]} {config[poolseq_sync_directory]}"

def get_files_to_gather(wildcards):
    job_ids = open(job_file_path).readlines()
    job_ids = [i.strip().replace(",", "_") for i in job_ids if i.strip() != ""]
    return [f"{config['working_directory']}/sub_vcfs/{job_id}.{wildcards.popSet}.{wildcards.method}.{wildcards.maf}.{wildcards.mac}.{wildcards.version}.vcf.gz" for job_id in job_ids if wildcards.chr in job_id]

rule gatherPoolSnp:
    input:
        get_files_to_gather
    output:
        expand("{wd}/sub_bcf/dest.{{chr}}.{{popSet}}.{{method}}.{{maf}}.{{mac}}.{{version}}.bcf", wd=config['working_directory'])
    resources:
        ntasks_per_node=20, time_limit=20
        # ntasks_per_node=20, array_size=1, time_limit=240
    shell:  "bash gather_poolsnp.sh {config[popSet]} {config[method]} {config[maf]} {config[mac]} {config[version]} {config[working_directory]} {wildcards.chr}"

rule annotate:
    input:
        expand("{wd}/sub_bcf/dest.{chr}.{{popset}}.{{method}}.{{maf}}.{{mac}}.{{version}}.bcf", wd=config['working_directory'], chr=CHRS)
    output:
        expand("{wd}/dest.{{popset}}.{{method}}.{{maf}}.{{mac}}.{{version}}.ann.vcf.gz", wd=config["working_directory"])
    resources:
        ntasks_per_node=10, time_limit=140, memory_limit=20
        # ntasks_per_node=10, time_limit=1440, memory_limit=20
    shell:  "bash annotate.sh {config[popSet]} {config[method]} {config[maf]} {config[mac]} {config[version]} {config[working_directory]}"
